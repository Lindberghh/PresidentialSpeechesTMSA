{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modelling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d75779517a0ca1a8"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:43:57.948775300Z",
     "start_time": "2023-10-04T22:43:57.935775200Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.matutils import corpus2csc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import html\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "data = pd.read_json('venv/data/presidential_speeches.json') # load data\n",
    "data.sort_values(by=['date'], inplace=True) # sort by data\n",
    "data.reset_index(drop=True, inplace=True) # reset index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:43:59.966707600Z",
     "start_time": "2023-10-04T22:43:59.776679200Z"
    }
   },
   "id": "81e927ca316e6aa7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add relevant metadata"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13fa00279adaa1e"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# sort presidents to their parties\n",
    "president_list = []\n",
    "for i in range(len(data['president'].unique())):\n",
    "    president_list.append(data['president'].unique()[i])\n",
    "parties_list= ['Federalist', 'Democratic-Republican', 'National Republican', 'Democratic', 'Whig', 'Republican', 'Democratic (Union)']\n",
    "sort_party = [0, 0, 1, 1, 1, 2, 3, 3, 4, 4, 3, 4, 4, 5, 3, 3, 6, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3]\n",
    "party = []\n",
    "for i in range(len(sort_party)):\n",
    "    party.append(parties_list[sort_party[i]])\n",
    "data['party'] = pd.Series(dtype='string')\n",
    "for i in range(len(president_list)):\n",
    "    data['party'][data['president'] == president_list[i]] = party[i]\n",
    "# assign each speech its respective era\n",
    "data['era'] = pd.Series(dtype='string')\n",
    "era_list = ['Early Republic', 'Jacksonian Democracy', 'Sectional Conflict', 'Gilded Age', 'Progressive Era', 'Depression and World Conflict', 'Social Change and Soviet Relations', 'Globalization']\n",
    "for i in range(len(data)):\n",
    "    if data['date'][i] < pd.Timestamp('1829-01-01T12'):\n",
    "        data['era'][i] =  era_list[0]\n",
    "    if pd.Timestamp('1829-01-01T12') <= data['date'][i] < pd.Timestamp('1853-01-01T12'):\n",
    "        data['era'][i] = era_list[1]\n",
    "    elif pd.Timestamp('1853-01-01T12') <= data['date'][i] < pd.Timestamp('1881-01-01T12'):\n",
    "        data['era'][i] = era_list[2]\n",
    "    elif pd.Timestamp('1881-01-01T12') <= data['date'][i] < pd.Timestamp('1897-01-01T12'):\n",
    "        data['era'][i] = era_list[3]\n",
    "    elif pd.Timestamp('1897-01-01T12') <= data['date'][i] < pd.Timestamp('1921-01-01T12'):\n",
    "        data['era'][i] = era_list[4]\n",
    "    elif pd.Timestamp('1921-01-01T12') <= data['date'][i] < pd.Timestamp('1961-01-01T12'):\n",
    "        data['era'][i] = era_list[5]\n",
    "    elif pd.Timestamp('1961-01-01T12') <= data['date'][i] < pd.Timestamp('1989-01-01T12'):\n",
    "        data['era'][i] = era_list[6]\n",
    "    elif pd.Timestamp('1989-01-01T12') <= data['date'][i]:\n",
    "        data['era'][i] = era_list[7]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:03.038416100Z",
     "start_time": "2023-10-04T22:44:02.827412400Z"
    }
   },
   "id": "5c697359139ae4f2"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "data['transcript'].replace(to_replace='(Applause.)', regex=True, value='', inplace=True)\n",
    "data['transcript'].replace(to_replace='(Laughter.)', regex=True, value='', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:06.101578Z",
     "start_time": "2023-10-04T22:44:04.601579200Z"
    }
   },
   "id": "b0c3ad2ac1f5781e"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enno\\AppData\\Local\\Temp/ipykernel_6540/3917522308.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['transcript'][i] = data['transcript'][i].replace('\\'', ' ')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    data['transcript'][i] = data['transcript'][i].replace('\\'', '')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:06.846578100Z",
     "start_time": "2023-10-04T22:44:06.722579700Z"
    }
   },
   "id": "761c8efae77f35cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "439c1005dabd237d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Following section is code written by Srikanth Shenoy and can be found under https://towardsdatascience.com/elegant-text-pre-processing-with-nltk-in-sklearn-pipeline-d6fe18b91eb8 (accessed on 02/10/2023)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "998f7a90e0e2bed4"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Enno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Enno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Enno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Enno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords, make lowercase, tokenize, lemmatize\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "custom_words = {'q'}\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(custom_words)\n",
    "\n",
    "def preprocess(text):\n",
    "    text = sent_tokenize(text)\n",
    "    for sen in text:\n",
    "        sen = sen.lower()\n",
    "        \n",
    "    #words = pos_tag(word_tokenize(text))\n",
    "    words = word_tokenize(sent_tokenize(text))\n",
    "    words = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    words = pos_tag(words)\n",
    "    \n",
    "    #for word, tag in words:\n",
    "    #print(words)\n",
    "    #words = [lemmatizer.lemmatize(word) for word in words[0] if word not in stop_words and word.isalpha()]\n",
    "    return words\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:10.239541800Z",
     "start_time": "2023-10-04T22:44:10.026943400Z"
    }
   },
   "id": "860fec2616684f0f"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import contractions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from unidecode import unidecode"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:12.028239100Z",
     "start_time": "2023-10-04T22:44:12.013244400Z"
    }
   },
   "id": "9507ca52d096d88c"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "def lemmatize_pos_tagged_text(text, lemmatizer, pos_tag_dict):\n",
    "  sentences = nltk.sent_tokenize(text)\n",
    "  new_sentences = []\n",
    "\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    new_sentence_words = []\n",
    "    #one pos_tuple for sentence\n",
    "    pos_tuples = nltk.pos_tag(nltk.word_tokenize(sentence)) \n",
    "\n",
    "    for word_idx, word in enumerate(nltk.word_tokenize(sentence)):\n",
    "      nltk_word_pos = pos_tuples[word_idx][1]\n",
    "      wordnet_word_pos = pos_tag_dict.get(\n",
    "                          nltk_word_pos[0].upper(), None)\n",
    "      if wordnet_word_pos is not None:\n",
    "        new_word = lemmatizer.lemmatize(word, wordnet_word_pos)\n",
    "      else:\n",
    "        new_word = lemmatizer.lemmatize(word)\n",
    "\n",
    "      new_sentence_words.append(new_word)\n",
    "\n",
    "    new_sentence = \" \".join(new_sentence_words)\n",
    "    new_sentences.append(new_sentence)\n",
    "\n",
    "  return \" \".join(new_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:14.568244500Z",
     "start_time": "2023-10-04T22:44:14.544249Z"
    }
   },
   "id": "fa478aed46ed3a23"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def download_if_non_existent(res_path, res_name):\n",
    "  try:\n",
    "    nltk.data.find(res_path)\n",
    "  except LookupError:\n",
    "    print(f'resource {res_path} not found. Downloading now...')\n",
    "    nltk.download(res_name)\n",
    "class NltkPreprocessingSteps:\n",
    "  def __init__(self, X):\n",
    "    self.X = X\n",
    "    download_if_non_existent('corpora/stopwords', 'stopwords')\n",
    "    download_if_non_existent('tokenizers/punkt', 'punkt')\n",
    "    download_if_non_existent('taggers/averaged_perceptron_tagger',\n",
    "                             'averaged_perceptron_tagger')\n",
    "    download_if_non_existent('corpora/wordnet', 'wordnet')\n",
    "    download_if_non_existent('corpora/omw-1.4', 'omw-1.4')\n",
    "\n",
    "    self.sw_nltk = stopwords.words('english')\n",
    "    new_stopwords = ['<*>']\n",
    "    self.sw_nltk.extend(new_stopwords)\n",
    "    self.sw_nltk.remove('not')\n",
    "\n",
    "    self.pos_tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "\n",
    "    # '!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~' 32 punctuations in python\n",
    "    # we dont want to replace . first time around\n",
    "    self.remove_punctuations = string.punctuation.replace('.','')\n",
    "\n",
    "  def remove_html_tags(self):\n",
    "    self.X = self.X.apply(\n",
    "            lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "    return self\n",
    "\n",
    "  def replace_diacritics(self):\n",
    "    self.X = self.X.apply(\n",
    "            lambda x: unidecode(x, errors=\"preserve\"))\n",
    "    return self\n",
    "\n",
    "  def to_lower(self):\n",
    "    self.X = np.apply_along_axis(lambda x: x.lower(), self.X)\n",
    "    return self\n",
    "\n",
    "  def expand_contractions(self):\n",
    "    self.X = self.X.apply(\n",
    "            lambda x: \" \".join([contractions.fix(expanded_word) \n",
    "                        for expanded_word in x.split()]))\n",
    "    return self\n",
    "\n",
    "  def remove_numbers(self):\n",
    "    self.X = self.X.apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "    return self\n",
    "\n",
    "  def replace_dots_with_spaces(self):\n",
    "    self.X = self.X.apply(lambda x: re.sub(\"[.]\", \" \", x))\n",
    "    return self\n",
    "\n",
    "  def remove_punctuations_except_periods(self):\n",
    "    self.X = self.X.apply(\n",
    "                 lambda x: re.sub('[%s]' %\n",
    "                  re.escape(self.remove_punctuations), '' , x))\n",
    "    return self\n",
    "\n",
    "  def remove_all_punctuations(self):\n",
    "    self.X = self.X.apply(lambda x: re.sub('[%s]' %\n",
    "                          re.escape(string.punctuation), '' , x))\n",
    "    return self\n",
    "\n",
    "  def remove_double_spaces(self):\n",
    "    self.X = self.X.apply(lambda x: re.sub(' +', ' ', x))\n",
    "    return self\n",
    "\n",
    "  def fix_typos(self):\n",
    "    self.X = self.X.apply(lambda x: str(TextBlob(x).correct()))\n",
    "    return self\n",
    "\n",
    "  def remove_stopwords(self):\n",
    "    # remove stop words from token list in each column\n",
    "    self.X = self.X.apply(\n",
    "            lambda x: \" \".join([ word for word in x.split() \n",
    "                     if word not in self.sw_nltk]) )\n",
    "    return self\n",
    "\n",
    "  def lemmatize(self):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    self.X = self.X.apply(lambda x: lemmatize_pos_tagged_text(\n",
    "                           x, lemmatizer, self.pos_tag_dict))\n",
    "    return self\n",
    "\n",
    "  def get_processed_text(self):\n",
    "    return self.X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T22:44:16.618371Z",
     "start_time": "2023-10-04T22:44:16.606370100Z"
    }
   },
   "id": "bca249665ff2dd0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource corpora/wordnet not found. Downloading now...\n",
      "resource corpora/omw-1.4 not found. Downloading now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Enno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Enno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "txt_preproc = NltkPreprocessingSteps(data['transcript'])\n",
    "processed_text = \\\n",
    "    txt_preproc \\\n",
    "    .remove_html_tags()\\\n",
    "    .replace_diacritics()\\\n",
    "    .expand_contractions()\\\n",
    "    .remove_numbers()\\\n",
    "    .fix_typos()\\\n",
    "    .remove_punctuations_except_periods()\\\n",
    "    .lemmatize()\\\n",
    "    .remove_double_spaces()\\\n",
    "    .remove_all_punctuations()\\\n",
    "    .remove_stopwords()\\\n",
    "    .get_processed_text()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-04T22:44:22.231085500Z"
    }
   },
   "id": "ce0caceec18dff47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-04T22:38:07.685579400Z"
    }
   },
   "id": "79e4da661fd5eba0"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "dictionary = Dictionary(preprocessed)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in preprocessed] "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T01:28:28.539087200Z",
     "start_time": "2023-10-04T01:28:25.668833300Z"
    }
   },
   "id": "cb49c2d399e49ee2"
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "chunksize = 5000\n",
    "passes = 1\n",
    "iterations = 400\n",
    "eval_every = None\n",
    "\n",
    "model = gensim.models.LdaModel(\n",
    "corpus=bow_corpus,\n",
    "id2word=dictionary,\n",
    "chunksize=chunksize,\n",
    "alpha='auto',\n",
    "eta='auto',\n",
    "iterations=iterations,\n",
    "num_topics=num_topics,\n",
    "passes=passes,\n",
    "eval_every=eval_every\n",
    ")\n",
    "topics = model.show_topics(\n",
    "num_topics=num_topics,\n",
    "num_words=10,\n",
    "log=False,\n",
    "formatted=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T01:28:57.151926Z",
     "start_time": "2023-10-04T01:28:28.545084100Z"
    }
   },
   "id": "a341567af2f4632c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c2bffad9b896b579"
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 0\n",
      "Words: ['going', 'program', 'help', 'applause', 'problem', 'federal', 'get', 'administration', 'south', 'child']\n",
      "topic: 1\n",
      "Words: ['applause', 'help', 'energy', 'iraq', 'constitution', 'man', 'family', 'back', 'problem', 'going']\n",
      "topic: 2\n",
      "Words: ['subject', 'increase', 'department', 'tax', 'report', 'trade', 'business', 'going', 'federal', 'provision']\n",
      "topic: 3\n",
      "Words: ['applause', 'treaty', 'report', 'person', 'secretary', 'job', 'get', 'department', 'going', 'territory']\n",
      "topic: 4\n",
      "Words: ['case', 'subject', 'treaty', 'money', 'tax', 'mexico', 'treasury', 'bank', 'amount', 'constitution']\n",
      "topic: 5\n",
      "Words: ['going', 'get', 'child', 'bill', 'business', 'man', 'party', 'treaty', 'family', 'federal']\n",
      "topic: 6\n",
      "Words: ['constitution', 'subject', 'department', 'officer', 'treaty', 'condition', 'court', 'secretary', 'commerce', 'trade']\n",
      "topic: 7\n",
      "Words: ['going', 'bank', 'help', 'job', 'get', 'governor', 'program', 'family', 'thank', 'back']\n",
      "topic: 8\n",
      "Words: ['tax', 'federal', 'business', 'constitution', 'condition', 'economic', 'party', 'administration', 'territory', 'program']\n",
      "topic: 9\n",
      "Words: ['business', 'constitution', 'man', 'subject', 'condition', 'applause', 'case', 'problem', 'help', 'value']\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in topics:\n",
    "    print('topic: {}'.format(topic_id))\n",
    "    print('Words: {}'.format([word for word, _ in topic]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T01:28:57.165921800Z",
     "start_time": "2023-10-04T01:28:57.155925200Z"
    }
   },
   "id": "69d7705edad6cb7c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bce151156d14b5fb"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "pp_test = data.loc[data['president'] == 'Donald Trump']['transcript'].apply(preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T17:25:06.074104900Z",
     "start_time": "2023-10-04T17:24:53.466106Z"
    }
   },
   "id": "862bc11357ccb1aa"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "'the'"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_test[995][0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T17:25:57.658580400Z",
     "start_time": "2023-10-04T17:25:57.641580100Z"
    }
   },
   "id": "8ce6fac8073fbce9"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "dictionary = Dictionary(pp_test)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in pp_test] \n",
    "num_topics = 10\n",
    "chunksize = 10000\n",
    "passes = 1\n",
    "iterations = 400\n",
    "eval_every = None\n",
    "\n",
    "model = gensim.models.LdaModel(\n",
    "corpus=bow_corpus,\n",
    "id2word=dictionary,\n",
    "chunksize=chunksize,\n",
    "alpha='auto',\n",
    "eta='auto',\n",
    "iterations=iterations,\n",
    "num_topics=num_topics,\n",
    "passes=passes,\n",
    "eval_every=eval_every\n",
    ")\n",
    "topics = model.show_topics(\n",
    "num_topics=num_topics,\n",
    "num_words=5,\n",
    "log=False,\n",
    "formatted=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T16:46:39.641220100Z",
     "start_time": "2023-10-04T16:46:38.828638700Z"
    }
   },
   "id": "8993e68ec042ce53"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 0\n",
      "Words: ['virus', 'governor', 'talking', 'yeah', 'ahead']\n",
      "topic: 1\n",
      "Words: ['tax', 'trump', 'reform', 'tonight', 'governor']\n",
      "topic: 2\n",
      "Words: ['immigration', 'tax', 'wall', 'reform', 'guy']\n",
      "topic: 3\n",
      "Words: ['biden', 'iran', 'trump', 'money', 'guy']\n",
      "topic: 4\n",
      "Words: ['governor', 'ahead', 'test', 'virus', 'question']\n",
      "topic: 5\n",
      "Words: ['test', 'okay', 'guy', 'money', 'tax']\n",
      "topic: 6\n",
      "Words: ['boy', 'trump', 'tonight', 'usa', 'violence']\n",
      "topic: 7\n",
      "Words: ['vote', 'money', 'okay', 'talking', 'wall']\n",
      "topic: 8\n",
      "Words: ['governor', 'test', 'ahead', 'virus', 'testing']\n",
      "topic: 9\n",
      "Words: ['tonight', 'approved', 'judge', 'death', 'tax']\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in topics:\n",
    "    print('topic: {}'.format(topic_id))\n",
    "    print('Words: {}'.format([word for word, _ in topic]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T16:46:40.762654Z",
     "start_time": "2023-10-04T16:46:40.757648Z"
    }
   },
   "id": "e0bd5c4b9020cb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b90f0b19237e3e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"j-hartmann/sentiment-roberta-large-english-3-classes\", top_k=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T16:18:51.960811500Z",
     "start_time": "2023-10-04T16:18:46.904015200Z"
    }
   },
   "id": "5c55312926ebadfb"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "['chief',\n 'justice',\n 'robert',\n 'president',\n 'carter',\n 'president',\n 'clinton',\n 'president',\n 'bush',\n 'president',\n 'obama',\n 'fellow',\n 'american',\n 'people',\n 'world',\n 'thank',\n 'citizen',\n 'america',\n 'joined',\n 'great',\n 'national',\n 'effort',\n 'rebuild',\n 'country',\n 'restore',\n 'promise',\n 'people',\n 'together',\n 'determine',\n 'course',\n 'america',\n 'world',\n 'year',\n 'come',\n 'face',\n 'challenge',\n 'confront',\n 'hardship',\n 'get',\n 'job',\n 'done',\n 'every',\n 'four',\n 'year',\n 'gather',\n 'step',\n 'carry',\n 'orderly',\n 'peaceful',\n 'transfer',\n 'power',\n 'grateful',\n 'president',\n 'obama',\n 'first',\n 'lady',\n 'michelle',\n 'obama',\n 'gracious',\n 'aid',\n 'throughout',\n 'transition',\n 'magnificent',\n 'today',\n 'ceremony',\n 'however',\n 'special',\n 'meaning',\n 'today',\n 'merely',\n 'transferring',\n 'power',\n 'one',\n 'administration',\n 'another',\n 'one',\n 'party',\n 'another',\n 'transferring',\n 'power',\n 'washington',\n 'giving',\n 'back',\n 'american',\n 'people',\n 'long',\n 'small',\n 'group',\n 'nation',\n 'capital',\n 'reaped',\n 'reward',\n 'government',\n 'people',\n 'borne',\n 'cost',\n 'washington',\n 'flourished',\n 'people',\n 'share',\n 'wealth',\n 'politician',\n 'prospered',\n 'job',\n 'left',\n 'factory',\n 'closed',\n 'establishment',\n 'protected',\n 'citizen',\n 'country',\n 'victory',\n 'victory',\n 'triumph',\n 'triumph',\n 'celebrated',\n 'nation',\n 'capital',\n 'little',\n 'celebrate',\n 'struggling',\n 'family',\n 'across',\n 'land',\n 'change',\n 'starting',\n 'right',\n 'right',\n 'moment',\n 'moment',\n 'belongs',\n 'belongs',\n 'everyone',\n 'gathered',\n 'today',\n 'everyone',\n 'watching',\n 'across',\n 'america',\n 'day',\n 'celebration',\n 'united',\n 'state',\n 'america',\n 'country',\n 'truly',\n 'matter',\n 'party',\n 'control',\n 'government',\n 'whether',\n 'government',\n 'controlled',\n 'people',\n 'january',\n 'remembered',\n 'day',\n 'people',\n 'became',\n 'ruler',\n 'nation',\n 'forgotten',\n 'men',\n 'woman',\n 'country',\n 'forgotten',\n 'longer',\n 'everyone',\n 'listening',\n 'came',\n 'ten',\n 'million',\n 'become',\n 'part',\n 'historic',\n 'movement',\n 'like',\n 'world',\n 'never',\n 'seen',\n 'center',\n 'movement',\n 'crucial',\n 'conviction',\n 'nation',\n 'exists',\n 'serve',\n 'citizen',\n 'american',\n 'want',\n 'great',\n 'school',\n 'child',\n 'safe',\n 'neighborhood',\n 'family',\n 'good',\n 'job',\n 'reasonable',\n 'demand',\n 'righteous',\n 'public',\n 'many',\n 'citizen',\n 'different',\n 'reality',\n 'exists',\n 'mother',\n 'child',\n 'trapped',\n 'poverty',\n 'inner',\n 'city',\n 'factory',\n 'scattered',\n 'like',\n 'tombstone',\n 'across',\n 'landscape',\n 'nation',\n 'education',\n 'system',\n 'flush',\n 'cash',\n 'leaf',\n 'young',\n 'beautiful',\n 'student',\n 'deprived',\n 'knowledge',\n 'crime',\n 'gang',\n 'drug',\n 'stolen',\n 'many',\n 'life',\n 'robbed',\n 'country',\n 'much',\n 'unrealized',\n 'potential',\n 'american',\n 'carnage',\n 'stop',\n 'right',\n 'stop',\n 'right',\n 'one',\n 'nation',\n 'pain',\n 'pain',\n 'dream',\n 'dream',\n 'success',\n 'success',\n 'share',\n 'one',\n 'heart',\n 'one',\n 'home',\n 'one',\n 'glorious',\n 'destiny',\n 'oath',\n 'office',\n 'take',\n 'today',\n 'oath',\n 'allegiance',\n 'american',\n 'many',\n 'decade',\n 'enriched',\n 'foreign',\n 'industry',\n 'expense',\n 'american',\n 'industry',\n 'subsidized',\n 'army',\n 'country',\n 'allowing',\n 'sad',\n 'depletion',\n 'military',\n 'defended',\n 'nation',\n 'border',\n 'refusing',\n 'defend',\n 'spent',\n 'trillion',\n 'dollar',\n 'overseas',\n 'america',\n 'infrastructure',\n 'fallen',\n 'disrepair',\n 'decay',\n 'made',\n 'country',\n 'rich',\n 'wealth',\n 'strength',\n 'confidence',\n 'country',\n 'disappeared',\n 'horizon',\n 'one',\n 'one',\n 'factory',\n 'shuttered',\n 'left',\n 'shore',\n 'even',\n 'thought',\n 'million',\n 'upon',\n 'million',\n 'american',\n 'worker',\n 'left',\n 'behind',\n 'wealth',\n 'middle',\n 'class',\n 'ripped',\n 'home',\n 'redistributed',\n 'across',\n 'entire',\n 'world',\n 'past',\n 'looking',\n 'future',\n 'assembled',\n 'today',\n 'issuing',\n 'new',\n 'decree',\n 'heard',\n 'every',\n 'city',\n 'every',\n 'foreign',\n 'capital',\n 'every',\n 'hall',\n 'power',\n 'day',\n 'forward',\n 'new',\n 'vision',\n 'govern',\n 'land',\n 'moment',\n 'going',\n 'america',\n 'first',\n 'every',\n 'decision',\n 'trade',\n 'tax',\n 'immigration',\n 'foreign',\n 'affair',\n 'made',\n 'benefit',\n 'american',\n 'worker',\n 'american',\n 'family',\n 'must',\n 'protect',\n 'border',\n 'ravage',\n 'country',\n 'making',\n 'product',\n 'stealing',\n 'company',\n 'destroying',\n 'job',\n 'protection',\n 'lead',\n 'great',\n 'prosperity',\n 'strength',\n 'fight',\n 'every',\n 'breath',\n 'body',\n 'never',\n 'ever',\n 'let',\n 'america',\n 'start',\n 'winning',\n 'winning',\n 'like',\n 'never',\n 'bring',\n 'back',\n 'job',\n 'bring',\n 'back',\n 'border',\n 'bring',\n 'back',\n 'wealth',\n 'bring',\n 'back',\n 'dream',\n 'build',\n 'new',\n 'road',\n 'highway',\n 'bridge',\n 'airport',\n 'tunnel',\n 'railway',\n 'across',\n 'wonderful',\n 'nation',\n 'get',\n 'people',\n 'welfare',\n 'back',\n 'work',\n 'rebuilding',\n 'country',\n 'american',\n 'hand',\n 'american',\n 'labor',\n 'follow',\n 'two',\n 'simple',\n 'rule',\n 'buy',\n 'american',\n 'hire',\n 'american',\n 'seek',\n 'friendship',\n 'goodwill',\n 'nation',\n 'world',\n 'understanding',\n 'right',\n 'nation',\n 'put',\n 'interest',\n 'first',\n 'seek',\n 'impose',\n 'way',\n 'life',\n 'anyone',\n 'rather',\n 'let',\n 'shine',\n 'example',\n 'everyone',\n 'follow',\n 'reinforce',\n 'old',\n 'alliance',\n 'form',\n 'new',\n 'one',\n 'unite',\n 'civilized',\n 'world',\n 'radical',\n 'islamic',\n 'terrorism',\n 'eradicate',\n 'completely',\n 'face',\n 'earth',\n 'bedrock',\n 'politics',\n 'total',\n 'allegiance',\n 'united',\n 'state',\n 'america',\n 'loyalty',\n 'country',\n 'rediscover',\n 'loyalty',\n 'open',\n 'heart',\n 'patriotism',\n 'room',\n 'prejudice',\n 'bible',\n 'tell',\n 'u',\n 'good',\n 'pleasant',\n 'god',\n 'people',\n 'live',\n 'together',\n 'must',\n 'speak',\n 'mind',\n 'openly',\n 'debate',\n 'disagreement',\n 'honestly',\n 'always',\n 'pursue',\n 'solidarity',\n 'america',\n 'united',\n 'america',\n 'totally',\n 'unstoppable',\n 'fear',\n 'protected',\n 'always',\n 'protected',\n 'protected',\n 'great',\n 'men',\n 'woman',\n 'military',\n 'law',\n 'enforcement',\n 'importantly',\n 'protected',\n 'god',\n 'finally',\n 'must',\n 'think',\n 'big',\n 'dream',\n 'even',\n 'bigger',\n 'america',\n 'understand',\n 'nation',\n 'living',\n 'long',\n 'striving',\n 'longer',\n 'accept',\n 'politician',\n 'talk',\n 'action',\n 'constantly',\n 'complaining',\n 'never',\n 'anything',\n 'time',\n 'empty',\n 'talk',\n 'arrives',\n 'hour',\n 'action',\n 'let',\n 'anyone',\n 'tell',\n 'done',\n 'challenge',\n 'match',\n 'heart',\n 'fight',\n 'spirit',\n 'america',\n 'fail',\n 'country',\n 'thrive',\n 'prosper',\n 'stand',\n 'birth',\n 'new',\n 'millennium',\n 'ready',\n 'unlock',\n 'mystery',\n 'space',\n 'free',\n 'earth',\n 'misery',\n 'disease',\n 'harness',\n 'energy',\n 'industry',\n 'technology',\n 'tomorrow',\n 'new',\n 'national',\n 'pride',\n 'stir',\n 'soul',\n 'lift',\n 'sight',\n 'heal',\n 'division',\n 'time',\n 'remember',\n 'old',\n 'wisdom',\n 'soldier',\n 'never',\n 'forget',\n 'whether',\n 'black',\n 'brown',\n 'white',\n 'bleed',\n 'red',\n 'blood',\n 'patriot',\n 'enjoy',\n 'glorious',\n 'freedom',\n 'salute',\n 'great',\n 'american',\n 'flag',\n 'whether',\n 'child',\n 'born',\n 'urban',\n 'sprawl',\n 'detroit',\n 'windswept',\n 'plain',\n 'nebraska',\n 'look',\n 'night',\n 'sky',\n 'fill',\n 'heart',\n 'dream',\n 'infused',\n 'breath',\n 'life',\n 'almighty',\n 'creator',\n 'american',\n 'every',\n 'city',\n 'near',\n 'far',\n 'small',\n 'large',\n 'mountain',\n 'mountain',\n 'ocean',\n 'ocean',\n 'hear',\n 'word',\n 'never',\n 'ignored',\n 'voice',\n 'hope',\n 'dream',\n 'define',\n 'american',\n 'destiny',\n 'courage',\n 'goodness',\n 'love',\n 'forever',\n 'guide',\n 'u',\n 'along',\n 'way',\n 'together',\n 'make',\n 'america',\n 'strong',\n 'make',\n 'america',\n 'wealthy',\n 'make',\n 'america',\n 'proud',\n 'make',\n 'america',\n 'safe',\n 'yes',\n 'together',\n 'make',\n 'america',\n 'great',\n 'thank',\n 'god',\n 'bless',\n 'god',\n 'bless',\n 'america']"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_test[986]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:22:19.837743600Z",
     "start_time": "2023-10-04T15:22:19.828746Z"
    }
   },
   "id": "d4ab4e5094e3f374"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "[[{'label': 'positive', 'score': 0.9995902180671692}]]"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis('You are cool')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T17:44:18.847957600Z",
     "start_time": "2023-10-04T17:44:18.665880100Z"
    }
   },
   "id": "a0e62c5ddd4d05e4"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6540/3474027460.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msent_tokenize\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtokenized_text\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msent_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'transcript'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m950\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mword_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokenized_text\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001B[0m in \u001B[0;36mword_tokenize\u001B[1;34m(text, language, preserve_line)\u001B[0m\n\u001B[0;32m    127\u001B[0m     \u001B[1;33m:\u001B[0m\u001B[0mtype\u001B[0m \u001B[0mpreserve_line\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    128\u001B[0m     \"\"\"\n\u001B[1;32m--> 129\u001B[1;33m     \u001B[0msentences\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mpreserve_line\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0msent_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    130\u001B[0m     return [\n\u001B[0;32m    131\u001B[0m         \u001B[0mtoken\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msentences\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[1;32min\u001B[0m \u001B[0m_treebank_word_tokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001B[0m in \u001B[0;36msent_tokenize\u001B[1;34m(text, language)\u001B[0m\n\u001B[0;32m    105\u001B[0m     \"\"\"\n\u001B[0;32m    106\u001B[0m     \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 107\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    108\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36mtokenize\u001B[1;34m(self, text, realign_boundaries)\u001B[0m\n\u001B[0;32m   1275\u001B[0m         \u001B[0mGiven\u001B[0m \u001B[0ma\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0msentences\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1276\u001B[0m         \"\"\"\n\u001B[1;32m-> 1277\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentences_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1278\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1279\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdebug_decisions\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36msentences_from_text\u001B[1;34m(self, text, realign_boundaries)\u001B[0m\n\u001B[0;32m   1332\u001B[0m         \u001B[0mfollows\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mperiod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1333\u001B[0m         \"\"\"\n\u001B[1;32m-> 1334\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspan_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1336\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_slices_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1332\u001B[0m         \u001B[0mfollows\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mperiod\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1333\u001B[0m         \"\"\"\n\u001B[1;32m-> 1334\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspan_tokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1336\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_slices_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36mspan_tokenize\u001B[1;34m(self, text, realign_boundaries)\u001B[0m\n\u001B[0;32m   1322\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrealign_boundaries\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1323\u001B[0m             \u001B[0mslices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_realign_boundaries\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mslices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1324\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0msentence\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mslices\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1325\u001B[0m             \u001B[1;32myield\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1326\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m_realign_boundaries\u001B[1;34m(self, text, slices)\u001B[0m\n\u001B[0;32m   1363\u001B[0m         \"\"\"\n\u001B[0;32m   1364\u001B[0m         \u001B[0mrealign\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1365\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0msentence1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence2\u001B[0m \u001B[1;32min\u001B[0m \u001B[0m_pair_iter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mslices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1366\u001B[0m             \u001B[0msentence1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mslice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mrealign\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msentence1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1367\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0msentence2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m_pair_iter\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m    317\u001B[0m     \u001B[0miterator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    318\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 319\u001B[1;33m         \u001B[0mprev\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    320\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    321\u001B[0m         \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001B[0m in \u001B[0;36m_slices_from_text\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m   1336\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_slices_from_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1337\u001B[0m         \u001B[0mlast_break\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1338\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mmatch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lang_vars\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mperiod_context_re\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfinditer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1339\u001B[0m             \u001B[0mcontext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"after_tok\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1340\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext_contains_sentbreak\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "tokenized_text=sent_tokenize(data['transcript'][950])\n",
    "word_tokenize(tokenized_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T18:02:52.303101400Z",
     "start_time": "2023-10-04T18:02:52.273103700Z"
    }
   },
   "id": "9824c16002bb6745"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b3cb325ff7e653c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "db57f78a103ff661"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'Thank you very much. Everybody, please have a seat. Thank you very much. Well, thank you. It is good to be back. () It is good to be back in New York, it is good to be back in the Great Hall at Cooper Union. () We’ve got some special guests here that I want to acknowledge. Congresswoman Carolyn Maloney is here in the house. () Governor David Paterson is here. () Attorney General Andrew Cuomo. () State Comptroller Thomas DiNapoli is here. () The Mayor of New York City, Michael Bloomberg. () Dr. George Campbell, Jr., president of Cooper Union. () And all the citywide elected officials who are here. Thank you very much for your attendance. It is wonderful to be back in Cooper Union, where generations of leaders and citizens have come to defend their ideas and contest their differences. It’s also good to be back in Lower Manhattan, a few blocks from Wall Street. () It really is good to be back, because Wall Street is the heart of our nation’s financial sector. Now, since I last spoke here two years ago, our country has been through a terrible trial. More than 8 million people have lost their jobs. Countless small businesses have had to shut their doors. Trillions of dollars in savings have been lost -- forcing seniors to put off retirement, young people to postpone college, entrepreneurs to give up on the dream of starting a company. And as a nation we were forced to take unprecedented steps to rescue the financial system and the broader economy. And as a result of the decisions we made -- some of which, let’s face it, were very unpopular -- we are seeing hopeful signs. A little more than one year ago we were losing an average of 750,000 jobs each month. Today, America is adding jobs again. One year ago the economy was shrinking rapidly. Today the economy is growing. In fact, we’ve seen the fastest turnaround in growth in nearly three decades. But you’re here and I’m here because we’ve got more work to do. Until this progress is felt not just on Wall Street but on Main Street we cannot be satisfied. Until the millions of our neighbors who are looking for work can find a job, and wages are growing at a meaningful pace, we may be able to claim a technical recovery -- but we will not have truly recovered. And even as we seek to revive this economy, it’s also incumbent on us to rebuild it stronger than before. We don’t want an economy that has the same weaknesses that led to this crisis. And that means addressing some of the underlying problems that led to this turmoil and devastation in the first place. Now, one of the most significant contributors to this recession was a financial crisis as dire as any we’ve known in generations -- at least since the ’30s. And that crisis was born of a failure of responsibility -- from Wall Street all the way to Washington -- that brought down many of the world’s largest financial firms and nearly dragged our economy into a second Great Depression. It was that failure of responsibility that I spoke about when I came to New York more than two years ago -- before the worst of the crisis had unfolded. It was back in 2007. And I take no satisfaction in noting that my comments then have largely been borne out by the events that followed. But I repeat what I said then because it is essential that we learn the lessons from this crisis so we don’t doom ourselves to repeat it. And make no mistake, that is exactly what will happen if we allow this moment to pass -- and that’s an outcome that is unacceptable to me and it’s unacceptable to you, the American people. () As I said on this stage two years ago, I believe in the power of the free market. I believe in a strong financial sector that helps people to raise capital and get loans and invest their savings. That’s part of what has made America what it is. But a free market was never meant to be a free license to take whatever you can get, however you can get it. That’s what happened too often in the years leading up to this crisis. Some -- and let me be clear, not all -- but some on Wall Street forgot that behind every dollar traded or leveraged there’s family looking to buy a house, or pay for an education, open a business, save for retirement. What happens on Wall Street has real consequences across the country, across our economy. I’ve spoken before about the need to build a new foundation for economic growth in the 21st century. And given the importance of the financial sector, Wall Street reform is an absolutely essential part of that foundation. Without it, our house will continue to sit on shifting sands, and our families, businesses, and the global economy will be vulnerable to future crises. That’s why I feel so strongly that we need to enact a set of updated, commonsense rules to ensure accountability on Wall Street and to protect consumers in our financial system. () Now, here’s the good news: A comprehensive plan to achieve these reforms has already passed the House of Representatives. () A Senate version is currently being debated, drawing on ideas from Democrats and Republicans. Both bills represent significant improvement on the flawed rules that we have in place today, despite the furious effort of industry lobbyists to shape this legislation to their special interests. And for those of you in the financial sector I m sure that some of these lobbyists work for you and they’re doing what they are being paid to do. But I’m here today specifically -- when I speak to the titans of industry here -- because I want to urge you to join us, instead of fighting us in this effort. () I’m here because I believe that these reforms are, in the end, not only in the best interest of our country, but in the best interest of the financial sector. And I’m here to explain what reform will look like, and why it matters. Now, first, the bill being considered in the Senate would create what we did not have before, and that is a way to protect the financial system and the broader economy and American taxpayers in the event that a large financial firm begins to fail. If there’s a Lehmans or an AIG, how can we respond in a way that doesn’t force taxpayers to pick up the tab or, alternatively, could bring down the whole system. In an ordinary local bank when it approaches insolvency, we’ve got a process, an orderly process through the FDIC, that ensures that depositors are protected, maintains confidence in the banking system, and it works. Customers and taxpayers are protected and owners and management lose their equity. But we don’t have that kind of process designed to contain the failure of a Lehman Brothers or any of the largest and most interconnected financial firms in our country. That’s why, when this crisis began, crucial decisions about what would happen to some of the world’s biggest companies -- companies employing tens of thousands of people and holding hundreds of billions of dollars in assets -- had to take place in hurried discussions in the middle of the night. And that’s why, to save the entire economy from an even worse catastrophe, we had to deploy taxpayer dollars. Now, much of that money has now been paid back and my administration has proposed a fee to be paid by large financial firms to recover all the money, every dime, because the American people should never have been put in that position in the first place. () But this is why we need a system to shut these firms down with the least amount of collateral damage to innocent people and innocent businesses. And from the start, I’ve insisted that the financial industry, not taxpayers, shoulder the costs in the event that a large financial company should falter. The goal is to make certain that taxpayers are never again on the hook because a firm is deemed “too big to fail.” Now, there’s a legitimate debate taking place about how best to ensure taxpayers are held harmless in this process. And that’s a legitimate debate, and I encourage that debate. But what’s not legitimate is to suggest that somehow the legislation being proposed is going to encourage future taxpayer bailouts, as some have claimed. That makes for a good sound bite, but it’s not factually accurate. It is not true. () In fact, the system as it stands -- the system as it stands is what led to a series of massive, costly taxpayer bailouts. And it’s only with reform that we can avoid a similar outcome in the future. In other words, a vote for reform is a vote to put a stop to taxpayer-funded bailouts. That’s the truth. End of story. And nobody should be fooled in this debate. () By the way, these changes have the added benefit of creating incentives within the industry to ensure that no one company can ever threaten to bring down the whole economy. To that end, the bill would also enact what’s known as the Volcker Rule -- and there’s a tall guy sitting in the front row here, Paul Volcker -- (applause) -- who we named it after. And it does something very simple: It places some limits on the size of banks and the kinds of risks that banking institutions can take. This will not only safeguard our system against crises, this will also make our system stronger and more competitive by instilling confidence here at home and across the globe. Markets depend on that confidence. Part of what led to the turmoil of the past two years was that in the absence of clear rules and sound practices, people didn’t trust that our system was one in which it was safe to invest or lend. As we’ve seen, that harms all of us. So by enacting these reforms, we’ll help ensure that our financial system -- and our economy -- continues to be the envy of the world. That’s the first thing, making sure that we can wind down one firm if it gets into trouble without bringing the whole system down or forcing taxpayers to fund a bailout. Number two, reform would bring new transparency to many financial markets. As you know, part of what led to this crisis was firms like AIG and others who were making huge and risky bets, using derivatives and other complicated financial instruments, in ways that defied accountability, or even common sense. In fact, many practices were so opaque, so confusing, so complex that the people inside the firms didn’t understand them, much less those who were charged with overseeing them. They weren’t fully aware of the massive bets that were being placed. That’s what led Warren Buffett to describe derivatives that were bought and sold with little oversight as “financial weapons of mass destruction.” That’s what he called them. And that’s why reform will rein in excess and help ensure that these kinds of transactions take place in the light of day. Now, there’s been a great deal of concern about these changes. So I want to reiterate: There is a legitimate role for these financial instruments in our economy. They can help allay risk and spur investment. And there are a lot of companies that use these instruments to that legitimate end -- they are managing exposure to fluctuating prices or currencies, fluctuating markets. For example, a business might hedge against rising oil prices by buying a financial product to secure stable fuel costs, so an airlines might have an interest in locking in a decent price. That’s how markets are supposed to work. The problem is these markets operated in the shadows of our economy, invisible to regulators, invisible to the public. So reckless practices were rampant. Risks accrued until they threatened our entire financial system. And that’s why these reforms are designed to respect legitimate activities but prevent reckless risk taking. That’s why we want to ensure that financial products like standardized derivatives are traded out in the open, in the full view of businesses, investors, and those charged with oversight. And I was encouraged to see a Republican senator join with Democrats this week in moving forward on this issue. That s a good sign. () That s a good sign. For without action, we’ll continue to see what amounts to highly-leveraged, loosely-monitored gambling in our financial system, putting taxpayers and the economy in jeopardy. And the only people who ought to fear the kind of oversight and transparency that we re proposing are those whose conduct will fail this scrutiny. Third, this plan would enact the strongest consumer financial protections ever. () And that s absolutely necessary because this financial crisis wasn’t just the result of decisions made in the executive suites on Wall Street; it was also the result of decisions made around kitchen tables across America, by folks who took on mortgages and credit cards and auto loans. And while it’s true that many Americans took on financial obligations that they knew or should have known they could not have afforded, millions of others were, frankly, duped. They were misled by deceptive terms and conditions, buried deep in the fine print. And while a few companies made out like bandits by exploiting their customers, our entire economy was made more vulnerable. Millions of people have now lost their homes. Tens of millions more have lost value in their homes. Just about every sector of our economy has felt the pain, whether you’re paving driveways in Arizona, or selling houses in Ohio, or you re doing home repairs in California, or you’re using your home equity to start a small business in Florida. That’s why we need to give consumers more protection and more power in our financial system. This is not about stifling competition, stifling innovation; it’s just the opposite. With a dedicated agency setting ground rules and looking out for ordinary people in our financial system, we will empower consumers with clear and concise information when they’re making financial decisions. So instead of competing to offer confusing products, companies will compete the old-fashioned way, by offering better products. And that will mean more choices for consumers, more opportunities for businesses, and more stability in our financial system. And unless your business model depends on bilking people, there is little to fear from these new rules. () Number four, the last key component of reform. These Wall Street reforms will give shareholders new power in the financial system. They will get what we call a say on pay, a voice with respect to the salaries and bonuses awarded to top executives. And the SEC will have the authority to give shareholders more say in corporate elections, so that investors and pension holders have a stronger role in determining who manages the company in which they’ve placed their savings. Now, Americans don’t begrudge anybody for success when that success is earned. But when we read in the past, and sometimes in the present, about enormous executive bonuses at firms -- even as they’re relying on assistance from taxpayers or they’re taking huge risks that threaten the system as a whole or their company is doing badly -- it offends our fundamental values. Not only that, some of the salaries and bonuses that we’ve seen creates perverse incentives to take reckless risks that contributed to the crisis. It’s what helped lead to a relentless focus on a company’s next quarter, to the detriment of its next year or its next decade. And it led to a situation in which folks with the most to lose -- stock and pension holders -- had the least to say in the process. And that has to change. () Let me close by saying this. I have laid out a set of Wall Street reforms. These are reforms that would put an end to taxpayer bailouts; that would bring complex financial dealings out of the shadows; that would protect consumers; and that would give shareholders more power in the financial system. But let’s face it, we also need reform in Washington. () And the debate -- the debate over these changes is a perfect example. I mean, we have seen battalions of financial industry lobbyists descending on Capitol Hill, firms spending millions to influence the outcome of this debate. We’ve seen misleading arguments and attacks that are designed not to improve the bill but to weaken or to kill it. We’ve seen a bipartisan process buckle under the weight of these withering forces, even as we‘ve produced a proposal that by all accounts is a commonsense, reasonable, non-ideological approach to target the root problems that led to the turmoil in our financial sector and ultimately in our entire economy. So we’ve seen business as usual in Washington, but I believe we can and must put this kind of cynical politics aside. We’ve got to put an end to it. That’s why I’m here today. () That’s why I’m here today. And to those of you who are in the financial sector, let me say this, we will not always see eye to eye. We will not always agree. But that doesn’t mean that we’ve got to choose between two extremes. We do not have to choose between markets that are unfettered by even modest protections against crisis, or markets that are stymied by onerous rules that suppress enterprise and innovation. That is a false choice. And we need no more proof than the crisis that we’ve just been through. You see, there has always been a tension between the desire to allow markets to function without interference and the absolute necessity of rules to prevent markets from falling out of kilter. But managing that tension, one that we’ve debated since the founding of this nation, is what has allowed our country to keep up with a changing world. For in taking up this debate, in figuring out how to apply well-worn principles with each new age, we ensure that we don’t tip too far one way or the other -- that our democracy remains as dynamic and our economy remains as dynamic as it has in the past. So, yes, this debate can be contentious. It can be heated. But in the end it serves only to make our country stronger. It has allowed us to adapt and to thrive. And I read a report recently that I think fairly illustrates this point. It’s from Time Magazine. I’m going to quote: “Through the great banking houses of Manhattan last week ran wild-eyed alarm. Big bankers stared at one another in anger and astonishment. A bill just passed… would rivet upon their institutions what they considered a monstrous system… such a system, they felt, would not only rob them of their pride of profession but would reduce all U.S. banking to its lowest level.” That appeared in Time Magazine in June of 1933. (and applause.) The system that caused so much consternation, so much concern was the Federal Deposit Insurance Corporation, also known as the FDIC, an institution that has successfully secured the deposits of generations of Americans. In the end, our system only works -- our markets are only free -- when there are basic safeguards that prevent abuse, that check excesses, that ensure that it is more profitable to play by the rules than to game the system. And that is what the reforms we’ve been proposing are designed to achieve -- no more, no less. And because that is how we will ensure that our economy works for consumers, that it works for investors, and that it works for financial institutions -- in other words, that it works for all of us -- that’s why we’re working so hard to get this stuff passed. This is the central lesson not only of this crisis but of our history. It’s what I said when I spoke here two years ago. Because ultimately, there is no dividing line between Main Street and Wall Street. We will rise or we will fall together as one nation. () And that is why I urge all of you to join me. I urge all of you to join me, to join those who are seeking to pass these commonsense reforms. And for those of you in the financial industry, I urge you to join me not only because it is in the interest of your industry, but also because it’s in the interest of your country. Thank you so much. God bless you, and God bless the United States of America. Thank you. () '"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transcript'][950]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:18:06.301169Z",
     "start_time": "2023-10-04T15:18:06.284841900Z"
    }
   },
   "id": "790a846368097c18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
